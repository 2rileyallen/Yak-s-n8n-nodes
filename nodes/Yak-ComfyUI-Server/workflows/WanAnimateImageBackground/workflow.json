{
  "57": {
    "inputs": {
      "image": "Head_Shot Adam Wells.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "63": {
    "inputs": {
      "video": "Avatar IV Video (online-video-cutter.com).mp4",
      "force_rate": 25,
      "custom_width": 576,
      "custom_height": 1024,
      "frame_load_cap": 0,
      "skip_first_frames": 0,
      "select_every_nth": 1,
      "format": "AnimateDiff"
    },
    "class_type": "VHS_LoadVideo",
    "_meta": {
      "title": "Load Video (Upload) ğŸ¥ğŸ…¥ğŸ…—ğŸ…¢"
    }
  },
  "204": {
    "inputs": {
      "frame_rate": [
        "224",
        5
      ],
      "loop_count": 0,
      "filename_prefix": "video",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": true,
      "trim_to_audio": true,
      "pingpong": false,
      "save_output": false,
      "images": [
        "233",
        0
      ],
      "audio": [
        "63",
        2
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Image Background"
    }
  },
  "206": {
    "inputs": {
      "model_name": "wan_2.1_vae.safetensors",
      "precision": "bf16"
    },
    "class_type": "WanVideoVAELoader",
    "_meta": {
      "title": "WanVideo VAE Loader"
    }
  },
  "207": {
    "inputs": {
      "images": [
        "235",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "208": {
    "inputs": {
      "blocks_to_swap": 25,
      "offload_img_emb": false,
      "offload_txt_emb": false,
      "use_non_blocking": true,
      "vace_blocks_to_swap": 0,
      "prefetch_blocks": 1,
      "block_swap_debug": false
    },
    "class_type": "WanVideoBlockSwap",
    "_meta": {
      "title": "WanVideo Block Swap"
    }
  },
  "209": {
    "inputs": {
      "model": [
        "218",
        0
      ],
      "lora": [
        "217",
        0
      ]
    },
    "class_type": "WanVideoSetLoRAs",
    "_meta": {
      "title": "WanVideo Set LoRAs"
    }
  },
  "210": {
    "inputs": {
      "model": [
        "209",
        0
      ],
      "block_swap_args": [
        "208",
        0
      ]
    },
    "class_type": "WanVideoSetBlockSwap",
    "_meta": {
      "title": "WanVideo Set BlockSwap"
    }
  },
  "211": {
    "inputs": {
      "clip_name": "clip_vision_h.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "212": {
    "inputs": {
      "model": "sam2.1_hiera_base_plus.safetensors",
      "segmentor": "video",
      "device": "cuda",
      "precision": "fp16"
    },
    "class_type": "DownloadAndLoadSAM2Model",
    "_meta": {
      "title": "(Down)Load SAM2Model"
    }
  },
  "213": {
    "inputs": {
      "vitpose_model": "vitpose-l-wholebody.onnx",
      "yolo_model": "yolov10m.onnx",
      "onnx_device": "CUDAExecutionProvider"
    },
    "class_type": "OnnxDetectionModelLoader",
    "_meta": {
      "title": "ONNX Detection Model Loader"
    }
  },
  "214": {
    "inputs": {
      "keep_model_loaded": false,
      "individual_objects": false,
      "sam2_model": [
        "212",
        0
      ],
      "image": [
        "220",
        0
      ],
      "bboxes": [
        "222",
        3
      ]
    },
    "class_type": "Sam2Segmentation",
    "_meta": {
      "title": "Sam2Segmentation"
    }
  },
  "215": {
    "inputs": {
      "strength_1": 1,
      "strength_2": 1,
      "crop": "center",
      "combine_embeds": "average",
      "force_offload": true,
      "tiles": 0,
      "ratio": 0.5,
      "clip_vision": [
        "211",
        0
      ],
      "image_1": [
        "235",
        0
      ]
    },
    "class_type": "WanVideoClipVisionEncode",
    "_meta": {
      "title": "WanVideo ClipVision Encode"
    }
  },
  "216": {
    "inputs": {
      "expand": 25,
      "incremental_expandrate": 0,
      "tapered_corners": true,
      "flip_input": false,
      "blur_radius": 0,
      "lerp_alpha": 1,
      "decay_factor": 1,
      "fill_holes": false,
      "mask": [
        "214",
        0
      ]
    },
    "class_type": "GrowMaskWithBlur",
    "_meta": {
      "title": "Grow Mask With Blur"
    }
  },
  "217": {
    "inputs": {
      "lora_0": "WanAnimate_relight_lora_fp16.safetensors",
      "strength_0": 1,
      "lora_1": "lightx2v_I2V_14B_480p_cfg_step_distill_rank64_bf16.safetensors",
      "strength_1": 1.2,
      "lora_2": "none",
      "strength_2": 1,
      "lora_3": "none",
      "strength_3": 1,
      "lora_4": "none",
      "strength_4": 1,
      "low_mem_load": false,
      "merge_loras": false
    },
    "class_type": "WanVideoLoraSelectMulti",
    "_meta": {
      "title": "WanVideo Lora Select Multi"
    }
  },
  "218": {
    "inputs": {
      "model": "Wan2_2-Animate-14B_fp8_e4m3fn_scaled_KJ.safetensors",
      "base_precision": "fp16_fast",
      "quantization": "disabled",
      "load_device": "offload_device",
      "attention_mode": "sdpa",
      "rms_norm_function": "default"
    },
    "class_type": "WanVideoModelLoader",
    "_meta": {
      "title": "WanVideo Model Loader"
    }
  },
  "220": {
    "inputs": {
      "image": [
        "63",
        0
      ]
    },
    "class_type": "GetImageSizeAndCount",
    "_meta": {
      "title": "Get Image Size & Count"
    }
  },
  "221": {
    "inputs": {
      "width": [
        "220",
        1
      ],
      "height": [
        "220",
        2
      ],
      "retarget_padding": 16,
      "body_stick_width": -1,
      "hand_stick_width": -1,
      "draw_head": "True",
      "pose_data": [
        "222",
        0
      ]
    },
    "class_type": "DrawViTPose",
    "_meta": {
      "title": "Draw ViT Pose"
    }
  },
  "222": {
    "inputs": {
      "width": [
        "220",
        1
      ],
      "height": [
        "220",
        2
      ],
      "model": [
        "213",
        0
      ],
      "images": [
        "220",
        0
      ]
    },
    "class_type": "PoseAndFaceDetection",
    "_meta": {
      "title": "Pose and Face Detection"
    }
  },
  "223": {
    "inputs": {
      "context_schedule": "static_standard",
      "context_frames": 81,
      "context_stride": 4,
      "context_overlap": 32,
      "freenoise": true,
      "verbose": false,
      "fuse_method": "linear"
    },
    "class_type": "WanVideoContextOptions",
    "_meta": {
      "title": "WanVideo Context Options"
    }
  },
  "224": {
    "inputs": {
      "video_info": [
        "63",
        3
      ]
    },
    "class_type": "VHS_VideoInfo",
    "_meta": {
      "title": "Video Info ğŸ¥ğŸ…¥ğŸ…—ğŸ…¢"
    }
  },
  "226": {
    "inputs": {
      "block_size": 32,
      "device": "cpu",
      "masks": [
        "216",
        0
      ]
    },
    "class_type": "BlockifyMask",
    "_meta": {
      "title": "Blockify Mask"
    }
  },
  "227": {
    "inputs": {
      "model_name": "umt5-xxl-enc-bf16.safetensors",
      "precision": "bf16",
      "positive_prompt": "A man with dark, wet, curly hair stands in a narrow alleyway in the rain, looking intensely at the camera. He is wearing a dark, hooded, waterproof jacket that is glistening with moisture The hood is down exposing his hair and face. The background is out of focus, with a warm light source creating a soft glow behind him, contrasting with the dark and moody atmosphere of the scene. A red brick wall is visible on the left side of the frame.",
      "negative_prompt": "è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°",
      "quantization": "disabled",
      "use_disk_cache": false,
      "device": "gpu"
    },
    "class_type": "WanVideoTextEncodeCached",
    "_meta": {
      "title": "WanVideo TextEncode Cached"
    }
  },
  "229": {
    "inputs": {
      "width": [
        "224",
        8
      ],
      "height": [
        "224",
        9
      ],
      "num_frames": [
        "224",
        6
      ],
      "force_offload": false,
      "frame_window_size": 77,
      "colormatch": "disabled",
      "pose_strength": 1,
      "face_strength": 1,
      "tiled_vae": false,
      "vae": [
        "206",
        0
      ],
      "clip_embeds": [
        "215",
        0
      ],
      "ref_images": [
        "235",
        0
      ],
      "pose_images": [
        "221",
        0
      ],
      "face_images": [
        "222",
        1
      ]
    },
    "class_type": "WanVideoAnimateEmbeds",
    "_meta": {
      "title": "WanVideo Animate Embeds"
    }
  },
  "230": {
    "inputs": {
      "steps": 4,
      "cfg": 1,
      "shift": 5,
      "seed": 326454980382193,
      "force_offload": true,
      "scheduler": "dpm++_sde",
      "riflex_freq_index": 0,
      "denoise_strength": 1,
      "batched_cfg": "",
      "rope_function": "comfy",
      "start_step": 0,
      "end_step": -1,
      "add_noise_to_samples": false,
      "model": [
        "210",
        0
      ],
      "image_embeds": [
        "229",
        0
      ],
      "text_embeds": [
        "227",
        0
      ]
    },
    "class_type": "WanVideoSampler",
    "_meta": {
      "title": "WanVideo Sampler"
    }
  },
  "232": {
    "inputs": {
      "enable_vae_tiling": false,
      "tile_x": 272,
      "tile_y": 272,
      "tile_stride_x": 144,
      "tile_stride_y": 128,
      "normalization": "default",
      "vae": [
        "206",
        0
      ],
      "samples": [
        "230",
        0
      ]
    },
    "class_type": "WanVideoDecode",
    "_meta": {
      "title": "WanVideo Decode"
    }
  },
  "233": {
    "inputs": {
      "image": [
        "232",
        0
      ]
    },
    "class_type": "GetImageSizeAndCount",
    "_meta": {
      "title": "Get Image Size & Count"
    }
  },
  "235": {
    "inputs": {
      "width": [
        "224",
        8
      ],
      "height": [
        "224",
        9
      ],
      "upscale_method": "lanczos",
      "keep_proportion": "pad_edge_pixel",
      "pad_color": "0, 0, 0",
      "crop_position": "top",
      "divisible_by": 16,
      "device": "cpu",
      "per_batch": 0,
      "image": [
        "57",
        0
      ]
    },
    "class_type": "ImageResizeKJv2",
    "_meta": {
      "title": "Resize Image v2"
    }
  },
  "236": {
    "inputs": {
      "color": "0, 0, 0",
      "device": "cpu",
      "image": [
        "63",
        0
      ],
      "mask": [
        "226",
        0
      ]
    },
    "class_type": "DrawMaskOnImage",
    "_meta": {
      "title": "Draw Mask On Image"
    }
  }
}